# You can get it from property yarn.resourcemanager.address from YARN
jobTracker=<AddHostName>:8050

# You can get it from property fs.defaultFS from HDFS
nameNode=hdfs://<AddHostName>:8020



#HDFS path where you need to copy workflow.xml and lib/*.jar to
oozie.wf.application.path=hdfs://<AddHostName>:8020/tmp/Spark_Oozie_example


#one of the values from Hadoop mapred.queue.names
queueName=default

oozie.use.system.libpath=true


# Input for Spark Job
numExecutors=3
driverMemory=4g
inputArgument=10

# If you have separate Queue for Spark, provide the spark Queue or set it to default.
sparkQueueName=default
